1.消息中间件原理是什么？
异步场景：在接受到用户请求后快速给出响应，随后去处理接下的业务
解耦场景：比如把下单处理流程，物流流程分开
削峰场景：主要延缓用户请求及层层过滤请求，最终在数据库访问的请求达到最少，
比如：使用消息队列削峰->用消息队列来缓存瞬间请求，把同步调用转成异步请求，先把请求缓存下来后，再通过mq平滑去推送出去消费。
流量削峰漏斗模式->尽量把数据量和请求量一层一层地过滤和减少(cdn-缓存系统-后台系统-db)
思想：就是在不同层次尽可能过滤无效请求，cdn 过滤大量图片和静态资源请求，再通过redis缓存过滤请求

2.常用的mq: ActiveMq  kafka rabbitMq  作用跟水库一样，拦截上游的洪水，削弱对下游的冲击。
ActiveMq：
kafka：吞吐量 大数据领域 实时计算 日志采集 每条数据至少会送一次，存在重发，用于消息传送管道
rabbitMq：在金融领域用的多，严谨性更高，数据丢失可能性低，具备高的实时性，用于数据交易管道

3.消息中间件缺点
系统可用性很低，系统引入的外部依赖越多稳定性越差
系统复杂度提供，mq会带来一系列的维护问题
一致性问题（A系统返回成功，人以为就成功了。BCD只有2个写成功了，C挂了，导致不一致）

4.如何保障消费者不丢失消息
RabbitMQ消息中间件默认是立马接受到订单信息就删除，这个是自动ack.假如在还未调用发货流程的时候，网络断了，用户迟迟等不到发货。
channel.basicConsume(
QUEUE_NAME, true, deliverCallback, consumerTag -> {}
);//只要把这个设置为flase，就会取消自动接收到消息立马删除，
我们可以手动ack确认接受到删除

5.ack机制
有自动ack机制
delivery tag：唯一的标识一次消息投递
ack批量机制
消息重发机制
手动ack机制
prefetch count过大致使内存溢出问题
prefetch count太小致使吞吐量太低
通过ack机制、消息重发等这套机制的落地实现，就可以保证一个消费者服务自身突然宕机、消息处理失败等场景下，都不会丢失数据。

6.消费的吞吐量百倍优化（防止消息积压）
在raabbit中有一个预取数，对于channel来接受生产消息都会有一个delivery tag 标识，在ack消息时候也会用到 这个tag，就知道是消费完哪个删除
在实际场景中，因为ack是一个异步过程是要时间处理的，如果开了批量消费的参数，这时可能会存在大量的unack.那么消息就会堆着消费者服务内存中积压。
解决：通过prefetch count 来控制unack消息条数，就是投递数unack+异步处理的unack+队列中的unack 要小于prefetch count，如果超过了，mq
就会终止发消息了。

7.mq在内存溢出的解决方案？
prefetch机制这个是一个限流操作，但是这个阈值多大，要结合场景，比如投递给消费者10万，如果是没有被消费状态，就会出现内存溢出，
rabbitmq 就会开启重启投递机制，也会把其他消费者搞的宕机，这样会形式雪崩反应。
如果设置太低，吞吐量就会很低，经验值是设置在100-300之间，这种情况，可以兼顾效率和内存不溢出。

7.保障消息传递的顺序性？
举例：在Mysql同步过程中，binlog日志文件通过mq上传后消费执行，如果有3条操作顺序：增加-修改-删除，如果顺序不能保证的话，就会导致结果出错
解决：在rabbitMq中在一个队列有3个消费者的情况下，其中B先执行，会导致AC全部错乱，
方法一：rabbitmq拆分多个队列，队列与消费者一对一，缺点：队列太多，不好维护
kafka是一个topic,一个partition,一个消费者，这种的吞吐量很低
写多个队列，相同key放一个队列，再多个线程来消费一个队列，这样保障顺序性
做到分配队列，单个消费者

9.怎么保障不重复消费？
造成重复消费原因：
每个消息者消费了mq里消息后，会发送一个确认消息给队列后进行消息删除，rabbitmq 是ack ,kafka是offset，但是在网络故障情况下，
确认消费的这个指令没有传送到。
如何解决：幂等性（一个请求来多次都不会改变结果）
比如这个消息Insert到表，给表设置一个主键
比如这个消息做redis中做set操作，无用特殊梳理，因为set多次还是一样的，set指令是自带幂等性
比如需要第三方交互消费记录，
涉及到钱 就用强校验：
设置一个全局ID，每次操作前用这个全局ID去流水表查，有结束流程
比如给人发短信属于弱校验
在 高并发的时候 可以 采用redis对消息id加锁

10.消息持久化
在rabbitmq中，有一个消息还会投递到消费者，就宕机后，这种情况下内存的消息就会丢失。
这就需要durable持久化机制。可以设置为true,RabbitMQ会把这queue的相关信息持久化的存储到磁盘上去，这样RabbitMQ重启后，就可以恢复持久化的queue。
